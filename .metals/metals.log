2024.06.17 10:29:11 INFO  Started: Metals version 1.3.1 in folders 'C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject' for client Visual Studio Code 1.90.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@5c04ae50]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@7f5be0a2]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@5c04ae50]
2024.06.17 10:29:11 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.17 10:29:12 INFO  no build target found for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.06.17 10:29:16 INFO  running 'C:\Users\janus\AppData\Local\Coursier\cache\arc\https\github.com\adoptium\temurin11-binaries\releases\download\jdk-11.0.23%252B9\OpenJDK11U-jdk_x64_windows_hotspot_11.0.23_9.zip\jdk-11.0.23+9\bin\java.exe -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar C:\Users\janus\AppData\Local\Temp\metals17558470242983754968\sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.17 10:29:18 INFO  [info] welcome to sbt 1.10.0 (Eclipse Adoptium Java 11.0.23)
2024.06.17 10:29:21 INFO  [info] loading settings for project demoproject-build-build from metals.sbt ...
2024.06.17 10:29:22 INFO  [info] loading project definition from C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\project\project
2024.06.17 10:29:24 INFO  [info] loading settings for project demoproject-build from metals.sbt ...
2024.06.17 10:29:24 INFO  [info] loading project definition from C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\project
2024.06.17 10:29:29 INFO  [success] Generated .bloop\demoproject-build.json
2024.06.17 10:29:29 INFO  [info] compiling 1 Scala source to C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\project\target\scala-2.12\sbt-1.0\classes ...
2024.06.17 10:29:29 INFO  [info] Non-compiled module 'compiler-bridge_2.12' for Scala 2.12.19. Compiling...
2024.06.17 10:29:47 INFO  [info]   Compilation completed in 17.984s.
2024.06.17 10:29:49 INFO  [info] done compiling
2024.06.17 10:29:49 INFO  [success] Total time: 25 s, completed 17 Jun 2024, 10:29:50
2024.06.17 10:29:53 INFO  [info] loading settings for project root from build.sbt ...
2024.06.17 10:29:53 INFO  [info] set current project to demoproject (in build file:/C:/Users/janus/OneDrive/Desktop/scala/practical%201/secondproject/demoproject/)
2024.06.17 10:30:36 INFO  [success] Generated .bloop\root.json
2024.06.17 10:30:36 INFO  [success] Generated .bloop\root-test.json
2024.06.17 10:30:36 INFO  [success] Total time: 43 s, completed 17 Jun 2024, 10:30:36
2024.06.17 10:30:36 INFO  time: ran 'sbt bloopInstall' in 1m20s
2024.06.17 10:30:36 INFO  Attempting to connect to the build server...
2024.06.17 10:30:36 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\.metals\bsp.trace.json or C:\Users\janus\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.17 10:30:46 INFO  no build target found for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.06.17 10:30:57 ERROR Timeout waiting for 'build/initialize' response
2024.06.17 10:30:57 WARN  Retrying connection to the build server Bloop
2024.06.17 10:30:57 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\.metals\bsp.trace.json or C:\Users\janus\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.17 10:30:57 INFO  Attempting to connect to the build server...
2024.06.17 10:30:57 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\project\.metals\bsp.trace.json or C:\Users\janus\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.17 10:30:57 INFO  time: Connected to build server in 20s
2024.06.17 10:30:57 INFO  Connected to Build server: Bloop v1.5.17
2024.06.17 10:31:51 INFO  time: indexed workspace in 54s
2024.06.17 10:31:51 INFO  compiling root (1 scala source)
2024.06.17 10:31:54 INFO  compiling root-test (1 scala source)
2024.06.17 10:31:54 INFO  time: compiled root in 2.6s
2024.06.17 10:31:54 INFO  time: compiled root-test in 0.69s
2024.06.17 10:33:22 INFO  compiling root (1 scala source)
2024.06.17 10:33:24 INFO  time: compiled root in 1.29s
2024.06.17 10:34:29 INFO  compiling root (1 scala source)
2024.06.17 10:34:29 INFO  time: compiled root in 0.44s
Jun 17, 2024 10:34:40 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 158
Jun 17, 2024 10:34:41 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 170
Jun 17, 2024 10:34:43 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 186
Jun 17, 2024 10:34:54 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 241
2024.06.17 10:35:27 INFO  compiling root (1 scala source)
2024.06.17 10:35:27 INFO  time: compiled root in 0.6s
2024.06.17 10:35:46 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Hell)
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:35:46 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("He)
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:35:46 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println(")
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:35:53 INFO  compiling root (1 scala source)
2024.06.17 10:35:53 INFO  time: compiled root in 0.34s
Jun 17, 2024 10:36:00 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 381
2024.06.17 10:36:43 INFO  compiling root (1 scala source)
2024.06.17 10:36:44 INFO  time: compiled root in 1.11s
2024.06.17 10:36:47 INFO  compiling root (1 scala source)
2024.06.17 10:36:47 INFO  time: compiled root in 0.91s
Jun 17, 2024 10:37:06 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 443
Jun 17, 2024 10:37:18 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 513
2024.06.17 10:38:02 INFO  compiling root (1 scala source)
2024.06.17 10:38:03 INFO  time: compiled root in 1.31s
Jun 17, 2024 10:39:08 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1024
Jun 17, 2024 10:39:08 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1025
Jun 17, 2024 10:39:08 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1026
Jun 17, 2024 10:39:08 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1028
Jun 17, 2024 10:39:08 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1030
2024.06.17 10:39:36 INFO  compiling root (1 scala source)
2024.06.17 10:39:37 INFO  time: compiled root in 1.1s
Jun 17, 2024 10:40:39 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1222
Jun 17, 2024 10:40:41 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1232
Jun 17, 2024 10:41:22 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1395
Jun 17, 2024 10:44:47 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1948
Jun 17, 2024 10:45:02 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2009
Jun 17, 2024 10:45:43 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2201
Jun 17, 2024 10:45:47 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2218
Jun 17, 2024 10:46:02 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2319
2024.06.17 10:46:12 INFO  compiling root (1 scala source)
2024.06.17 10:46:12 INFO  time: compiled root in 0.25s
2024.06.17 10:46:51 INFO  compiling root (1 scala source)
2024.06.17 10:46:52 INFO  time: compiled root in 1.14s
2024.06.17 10:48:18 INFO  compiling root (1 scala source)
2024.06.17 10:48:19 INFO  time: compiled root in 1.09s
Jun 17, 2024 10:49:41 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2916
Jun 17, 2024 10:50:19 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3115
Jun 17, 2024 10:50:19 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3114
Jun 17, 2024 10:50:20 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3130
Jun 17, 2024 10:50:20 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3132
Jun 17, 2024 10:50:20 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3131
Jun 17, 2024 10:50:20 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3137
Jun 17, 2024 10:50:35 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3277
2024.06.17 10:51:09 INFO  compiling root (1 scala source)
2024.06.17 10:51:10 INFO  time: compiled root in 1.02s
2024.06.17 10:51:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Total runnineasy(2) + tempo(3) + easy(2))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:51:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Totaeasy(2) + tempo(3) + easy(2))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:51:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Teasy(2) + tempo(3) + easy(2))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:51:36 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("easy(2) + tempo(3) + easy(2))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:51:38 INFO  compiling root (1 scala source)
2024.06.17 10:51:39 INFO  time: compiled root in 1.12s
2024.06.17 10:52:04 INFO  compiling root (1 scala source)
2024.06.17 10:52:04 INFO  time: compiled root in 0.85s
2024.06.17 10:52:39 INFO  compiling root (1 scala source)
2024.06.17 10:52:39 INFO  time: compiled root in 0.33s
2024.06.17 10:55:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Total running time: + ${easy(2) + tempo(3) + easy(2)})
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:55:45 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Total running time: + ${easy(2) + tempo(3) + easy(2)}"")
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:55:46 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Total running time: + ${easy(2) + tempo(3) + easy(2)})
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:55:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Total running time: + ${easy(2) + tempo(3) + easy(2)}"")
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:55:52 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Total running time: + ${easy(2) + tempo(3) + easy(2)}"")
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:55:53 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Total running time: + ${easy(2) + tempo(3) + easy(2)})
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:55:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Total running time: + ${easy(2) + tempo(3) + easy(2)}"")
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:55:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    println("Total running time: + ${easy(2) + tempo(3) + easy(2)})
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:57:03 INFO  compiling root (1 scala source)
2024.06.17 10:57:03 INFO  time: compiled root in 0.93s
2024.06.17 10:57:58 INFO  compiling root (1 scala source)
2024.06.17 10:57:58 INFO  time: compiled root in 0.98s
2024.06.17 10:59:15 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("area(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:16 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Tarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:17 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Toarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:19 INFO  compiling root (1 scala source)
2024.06.17 10:59:19 INFO  time: compiled root in 99ms
2024.06.17 10:59:19 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Toarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:23 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("oarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:24 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Aroarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:24 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Areaoarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:25 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Area oarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:25 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Area ooarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:26 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Area of oarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:25 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Area of toarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:26 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Area of the oarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:28 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Area of the dioarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:28 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Area of the disoarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:29 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Area of the diskoarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:30 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Area of the disk:oarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 10:59:31 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:3: error: unclosed string literal
    println("Area of the disk: oarea(4))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

Jun 17, 2024 10:59:39 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4220
2024.06.17 11:00:41 INFO  compiling root (1 scala source)
2024.06.17 11:00:41 INFO  time: compiled root in 0.28s
2024.06.17 11:01:21 INFO  compiling root (1 scala source)
2024.06.17 11:01:22 INFO  time: compiled root in 1.5s
2024.06.17 11:03:31 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"fah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:33 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Tefah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:33 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Tempfah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:33 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperfah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperafah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:36 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperatfah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:36 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperatufah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:36 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperaturefah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:37 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature fah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:38 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature infah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:39 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in fah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:40 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Ffah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in FHfah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Ffah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Fahfah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:44 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Fahrefah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:45 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Fahrenhfah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:45 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Fahrenhefah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:46 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Fahrenheifah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:46 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Fahrenheitfah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Fahrenheit:fah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:49 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Fahrenheit: fah(35))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:50 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Fahrenheit: $fah(35))
                                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: unclosed string interpolation
  }
   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:57 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string interpolation
    println(s"Temperature in Fahrenheit: ${fah(35)})
                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:03:58 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: unclosed string literal
    println(s"Temperature in Fahrenheit: ${fah(35)}"")
                                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"volume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Cvolume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Vvolume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volvolume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volumevolume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volume volume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:45 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volume ovolume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:45 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volume of volume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volume of spvolume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volume of sphevolume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volume of spherevolume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volume of sphere: volume(5))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volume of sphere: $volume(5))
                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: unclosed string interpolation
  }
   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string interpolation
    println(s"Volume of sphere: ${volume(5)})
                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:09:55 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: unclosed string literal
    println(s"Volume of sphere: ${volume(5)}"")
                                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:02 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"totalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Ttotalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Tototalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:04 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Totatotalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:04 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total totalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:05 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total costotalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:05 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost totalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost ototalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost of totalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:07 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost of 6totalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost of 60totalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost of 60 btotalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost of 60 booktotalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:10 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost of 60 bookstotalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:12 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost of 60 books: totalcost(60))
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost of 60 books: $totalcost(60))
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: unclosed string interpolation
  }
   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:17 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    println(s"Total cost of 60 books: ${totalcost(60)})
                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:19 ERROR Failed to tokenize input for semantic tokens for C:\Users\janus\OneDrive\Desktop\scala\practical 1\secondproject\demoproject\src\main\scala\example\Hello.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string literal
    println(s"Total cost of 60 books: ${totalcost(60)}"")
                                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.17 11:10:29 INFO  compiling root (1 scala source)
2024.06.17 11:10:30 INFO  time: compiled root in 1.06s
